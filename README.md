# Mitm-proxy-directions-from-gpt4

(Pardon my English; this is not my native language.)

A mitm script that perform a Arp poisening on subnet with sslstrip function built in, in Python, first generated by chatgpt (3.5), became a partially functional script. In that process, I noticed funny behavior on the side of chatgpt, namely that the arp poisoning function was done in such a way that it seemed to perform the function, but in reality, chatgpt made it look so, but it was not doing any form of arp profiling, so basically, chatgpt lied.

I confronted chatgpt with this lie, he said, then apologized and made it send only two ARP packages. The process from then on became easier, and he quickly made the polishing go on (even so well that if the script stopped the poisining would not stop, I would see it in Wireshark).
 
Also in the sslstrip function, he made a lie and simulated it, but after confronting it with this lie," he made it work. The 3.5 version i tested in visual code, and in realtime in my own netwerk.

After that, I copied that version of the script in Bing Chat (the GPT4 version) and asked him to correct it and make it better.
So he made it more complex, plus I asked him to come up with functions to make it perform better; he did this in the form of the AI intrusion detection system.

This is the draft I got from Bing. I'm going to test this, and then look how much further Bing Chat can bring this. When I asked him to make a function for the user to inject malicious code into the packages, he said it was time to stop and go on in a new chat. I geuss with the correct prompting i could at it, i could ask for instance is there a way to inject code in the packages. 

Also, the history of the prompt in Chatgpt is not completely accessible Anymore, for obvious reasons, I must say that all this was a form of test to see how far GPS would go with the correct prompting.
 
I will try to add the complete Chatgpt and Bing chat sessions to this repository.
 
